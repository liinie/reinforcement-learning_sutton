\chapter{动态规划}

动态规划(Dynamic Programming简称(DP))是一种算法的总称。
给定一个完美的环境模型作为马尔可夫决策过程(Markov decision process (MDP))，这种算法可以计算出最有策略。
经典的动态规划算法在强化学习中被应用得很少，一是因为要已知完美模型，二是因为计算量很大，但在理论上这种算法仍然很重要。
动态规划为理解本书呈现的方法提供了必不可少的基础。
事实上，所有这些方法都可以被视为为达到动态规划同等效果的尝试，只不过它们的计算量较少，也不需要完美的环境模型。

从这章开始，我们通常会假设环境是一个有限的MDP。
我们假设它的状态集，动作集，和奖励集，$\mathcal{S, A, R}$ 是有限的，它的动态(dynamics)是由一个概率集给予的 $p(s', r|s, a)$, 对所有$s \in \mathcal{S}, a \in \mathcal{A}(s), r \in \mathcal{R}$ 和$s' \in \mathcal{S^+}$ ($\mathcal{S^+}$是$\mathcal{S}$加上最终状态，如果问题是情节性任务(episodic tasks))。



[....Sachen kommen noch!]
